{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huangeunchong/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/huangeunchong/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/huangeunchong/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/huangeunchong/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/huangeunchong/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/huangeunchong/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/huangeunchong/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/huangeunchong/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/huangeunchong/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/huangeunchong/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/huangeunchong/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/huangeunchong/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n",
      "/Users/huangeunchong/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "import pathlib\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from keras.layers import Input, Dense    #using set model component\n",
    "from keras.models import Model    #using set model \n",
    "from keras.utils import plot_model    #show model structure\n",
    "from keras import layers as Layer\n",
    "import keras \n",
    "from pandas import DataFrame as df\n",
    "from keras.callbacks import EarlyStopping\n",
    "import gzip\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Dropout, Input, Activation, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_correct(predict, y):\n",
    "    result = {}\n",
    "    result['True-Positive'] = 0\n",
    "    result['True-Negative'] = 0\n",
    "    result['False-Negative'] = 0\n",
    "    result['False-Positive'] = 0\n",
    "\n",
    "    for i in range(len(predict)) :\n",
    "        if predict[i] == y[i] :\n",
    "            if y[i] == 0 :\n",
    "                result['True-Negative'] += 1\n",
    "            else :\n",
    "                result['True-Positive'] += 1\n",
    "        else :\n",
    "            if y[i] == 0 :\n",
    "                result['False-Positive'] += 1\n",
    "            else :\n",
    "                result['False-Negative'] += 1\n",
    "\n",
    "    for result_k, result_v in result.items():\n",
    "        print(result_k +\" : \"+ str(result_v))\n",
    "    \n",
    "    acc=(result['True-Positive']+result['True-Negative'])/len(y)\n",
    "    sensitivity=result['True-Positive']/(result['True-Positive']+result['False-Negative'])\n",
    "    specificity=result['True-Negative']/(result['True-Negative']+result['False-Positive'])\n",
    "    print(\"Accuracy :\", acc)\n",
    "    print(\"Sensitivity :\", sensitivity)\n",
    "    print(\"Specificity :\", specificity)\n",
    "    return acc, sensitivity, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(x, model, y):\n",
    "    hypo = model.predict_proba(x)\n",
    "    pred = np.where(df(hypo)[1] > 0.5, 1, 0).flatten()\n",
    "    acc, sen, spe=check_correct(pred, y)\n",
    "    auc=metrics.roc_auc_score(y, df(hypo)[1])\n",
    "    \n",
    "    \n",
    "    df_hypo=df(hypo)[1]\n",
    "    df_hypo.columns=['hypothesis 1']\n",
    "    \n",
    "    df_pred=df(pred)\n",
    "    df_pred.columns=['prediction']\n",
    "    \n",
    "    df_y=df(y)\n",
    "    df_y.columns=['y']\n",
    "    \n",
    "    pred_result=pd.concat([df_y,df_hypo, df_pred],axis=1)\n",
    "    \n",
    "    print(\"Accuracy : \",acc)\n",
    "    print(\"AUC : \",auc)\n",
    "    print(\" \")\n",
    "    print(df(pd.crosstab(y, pred, rownames=['Actual'], colnames=['Predicted'], margins=True)))\n",
    "    print(\" \")\n",
    "    print(df(pred_result))\n",
    "\n",
    "    return acc ,sen, spe ,auc, pred_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance_DNN(x, model, y):\n",
    "    hypo = model.predict(x)\n",
    "    pred = np.where(hypo > 0.5, 1, 0).flatten()\n",
    "    acc, sen, spe=check_correct(pred, y)\n",
    "    auc=metrics.roc_auc_score(y, hypo)\n",
    "    \n",
    "    df_hypo=df(hypo)\n",
    "    df_hypo.columns=['hypothesis 1']\n",
    "    \n",
    "    df_pred=df(pred)\n",
    "    df_pred.columns=['prediction']\n",
    "    \n",
    "    df_y=df(y)\n",
    "    df_y.columns=['y']\n",
    "    \n",
    "    pred_result=pd.concat([df_y,df_hypo, df_pred],axis=1)\n",
    "    \n",
    "    print(\"Accuracy : \",acc)\n",
    "    print(\"AUC : \",auc)\n",
    "    print(\" \")\n",
    "    print(df(pd.crosstab(y, pred, rownames=['Actual'], colnames=['Predicted'], margins=True)))\n",
    "    print(\" \")\n",
    "    print(df(pred_result))\n",
    "\n",
    "    return acc ,sen, spe ,auc, pred_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Model\n",
    "##### Classification 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SampleID</th>\n",
       "      <th>SSPG</th>\n",
       "      <th>SSPG_classification</th>\n",
       "      <th>A1C</th>\n",
       "      <th>GLU</th>\n",
       "      <th>AG</th>\n",
       "      <th>ALB.x</th>\n",
       "      <th>ALKP</th>\n",
       "      <th>BASO</th>\n",
       "      <th>BASOAB</th>\n",
       "      <th>...</th>\n",
       "      <th>ZSWIM7</th>\n",
       "      <th>ZSWIM8</th>\n",
       "      <th>ZSWIM8.AS1</th>\n",
       "      <th>ZXDA</th>\n",
       "      <th>ZXDB</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZEF1</th>\n",
       "      <th>ZZZ3</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ZJTKAE3-02</td>\n",
       "      <td>162.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>89</td>\n",
       "      <td>6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>99</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.885177</td>\n",
       "      <td>5.147299</td>\n",
       "      <td>7.673803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.151853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.755996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ZJTKAE3-04</td>\n",
       "      <td>162.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>98</td>\n",
       "      <td>8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>80</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>4.259629</td>\n",
       "      <td>8.062151</td>\n",
       "      <td>8.216878</td>\n",
       "      <td>2.009271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.009271</td>\n",
       "      <td>2.009271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ZJTKAE3-06</td>\n",
       "      <td>162.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>91</td>\n",
       "      <td>12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>67</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>4.434087</td>\n",
       "      <td>5.784487</td>\n",
       "      <td>7.768989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.552295</td>\n",
       "      <td>0.717454</td>\n",
       "      <td>2.462038</td>\n",
       "      <td>0.717454</td>\n",
       "      <td>0.717454</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ZJTKAE3-2012</td>\n",
       "      <td>162.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>94</td>\n",
       "      <td>5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>83</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.076022</td>\n",
       "      <td>5.602978</td>\n",
       "      <td>7.817027</td>\n",
       "      <td>1.193186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.716583</td>\n",
       "      <td>2.076022</td>\n",
       "      <td>1.193186</td>\n",
       "      <td>0.716583</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ZJTKAE3-2013</td>\n",
       "      <td>162.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>92</td>\n",
       "      <td>9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>73</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>2.538052</td>\n",
       "      <td>5.708347</td>\n",
       "      <td>8.232187</td>\n",
       "      <td>1.767240</td>\n",
       "      <td>1.379998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.513165</td>\n",
       "      <td>0.849071</td>\n",
       "      <td>0.849071</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>338</td>\n",
       "      <td>ZYXQKWY-05</td>\n",
       "      <td>158.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>79</td>\n",
       "      <td>11</td>\n",
       "      <td>4.2</td>\n",
       "      <td>73</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.544607</td>\n",
       "      <td>5.070096</td>\n",
       "      <td>8.032021</td>\n",
       "      <td>2.755259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339</td>\n",
       "      <td>ZYXQKWY-06</td>\n",
       "      <td>158.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>94</td>\n",
       "      <td>11</td>\n",
       "      <td>3.9</td>\n",
       "      <td>68</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.382445</td>\n",
       "      <td>6.819696</td>\n",
       "      <td>8.224836</td>\n",
       "      <td>1.747215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.181309</td>\n",
       "      <td>1.123368</td>\n",
       "      <td>2.181309</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>ZYXQKWY-07</td>\n",
       "      <td>158.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>85</td>\n",
       "      <td>6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>63</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>2.413523</td>\n",
       "      <td>7.612855</td>\n",
       "      <td>7.705503</td>\n",
       "      <td>1.288405</td>\n",
       "      <td>2.413523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.957973</td>\n",
       "      <td>1.288405</td>\n",
       "      <td>1.288405</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>341</td>\n",
       "      <td>ZYXQKWY-08</td>\n",
       "      <td>158.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>57</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.859655</td>\n",
       "      <td>5.069710</td>\n",
       "      <td>7.327889</td>\n",
       "      <td>1.394629</td>\n",
       "      <td>0.859655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.342845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>342</td>\n",
       "      <td>ZYXQKWY-09</td>\n",
       "      <td>158.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>96</td>\n",
       "      <td>9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>52</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.991522</td>\n",
       "      <td>8.022152</td>\n",
       "      <td>7.919469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.797662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.991522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>343 rows × 10787 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SampleID   SSPG  SSPG_classification  A1C  GLU  AG  ALB.x  ALKP  \\\n",
       "0      ZJTKAE3-02  162.0                    1  5.5   89   6    3.9    99   \n",
       "1      ZJTKAE3-04  162.0                    1  5.2   98   8    4.1    80   \n",
       "2      ZJTKAE3-06  162.0                    1  5.5   91  12    4.0    67   \n",
       "3    ZJTKAE3-2012  162.0                    1  5.1   94   5    4.2    83   \n",
       "4    ZJTKAE3-2013  162.0                    1  5.0   92   9    4.2    73   \n",
       "..            ...    ...                  ...  ...  ...  ..    ...   ...   \n",
       "338    ZYXQKWY-05  158.5                    1  5.1   79  11    4.2    73   \n",
       "339    ZYXQKWY-06  158.5                    1  5.2   94  11    3.9    68   \n",
       "340    ZYXQKWY-07  158.5                    1  5.1   85   6    3.9    63   \n",
       "341    ZYXQKWY-08  158.5                    1  5.3   99   6    3.7    57   \n",
       "342    ZYXQKWY-09  158.5                    1  5.7   96   9    3.8    52   \n",
       "\n",
       "     BASO  BASOAB  ...    ZSWIM7    ZSWIM8  ZSWIM8.AS1      ZXDA      ZXDB  \\\n",
       "0     0.5    0.03  ...  3.885177  5.147299    7.673803  0.000000  0.000000   \n",
       "1     0.7    0.03  ...  4.259629  8.062151    8.216878  2.009271  0.000000   \n",
       "2     0.9    0.05  ...  4.434087  5.784487    7.768989  0.000000  1.552295   \n",
       "3     1.1    0.05  ...  2.076022  5.602978    7.817027  1.193186  0.000000   \n",
       "4     0.6    0.04  ...  2.538052  5.708347    8.232187  1.767240  1.379998   \n",
       "..    ...     ...  ...       ...       ...         ...       ...       ...   \n",
       "338   1.0    0.06  ...  1.544607  5.070096    8.032021  2.755259  0.000000   \n",
       "339   0.4    0.03  ...  3.382445  6.819696    8.224836  1.747215  0.000000   \n",
       "340   0.6    0.04  ...  2.413523  7.612855    7.705503  1.288405  2.413523   \n",
       "341   0.7    0.05  ...  0.859655  5.069710    7.327889  1.394629  0.859655   \n",
       "342   0.4    0.03  ...  1.991522  8.022152    7.919469  0.000000  2.797662   \n",
       "\n",
       "         ZXDC       ZYX     ZZEF1      ZZZ3  index  \n",
       "0    0.000000  2.151853  0.000000  0.755996      1  \n",
       "1    2.009271  2.009271  0.000000  0.000000      2  \n",
       "2    0.717454  2.462038  0.717454  0.717454      3  \n",
       "3    0.716583  2.076022  1.193186  0.716583      2  \n",
       "4    0.000000  3.513165  0.849071  0.849071      2  \n",
       "..        ...       ...       ...       ...    ...  \n",
       "338  0.000000  0.000000  0.000000  0.000000      4  \n",
       "339  0.000000  2.181309  1.123368  2.181309      3  \n",
       "340  0.000000  1.957973  1.288405  1.288405      2  \n",
       "341  0.000000  2.342845  0.000000  0.000000      4  \n",
       "342  0.000000  1.991522  0.000000  0.000000      5  \n",
       "\n",
       "[343 rows x 10787 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"./IRIS_train.csv\")\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of Training Data\n",
      "Samples : 343\n",
      "Features : 10783\n"
     ]
    }
   ],
   "source": [
    "value= dataframe.drop([\"SampleID\", \"SSPG_classification\", \"SSPG\", \"index\"],axis=1)\n",
    "interest = dataframe.SSPG_classification\n",
    "\n",
    "print(\"Information of Training Data\")\n",
    "print(\"Samples : {}\".format(value.shape[0]))\n",
    "print(\"Features : {}\".format(value.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MinMax\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X = np.array(value)\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_MinMax = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(X_MinMax, interest, test_size=0.2, random_state=3, stratify=interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=350, max_depth=5, min_samples_split=4, random_state=10)\n",
    "abc = AdaBoostClassifier(n_estimators=250, random_state=0, learning_rate=0.05)\n",
    "gbc = GradientBoostingClassifier(n_estimators=350, learning_rate=0.05, random_state=10, min_samples_split=5)\n",
    "xgb_clf = xgb.XGBClassifier(n_estimators=100, max_depth=5,learning_rate=0.05, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.05, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=10,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(train_x, train_y)\n",
    "abc.fit(train_x, train_y)\n",
    "gbc.fit(train_x, train_y)\n",
    "xgb_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "# Random forest\n",
    "y_pred_rfc = rfc.predict_proba(test_x)[:,1]\n",
    "fpr_rfc, tpr_rfc, thresholds_rfc = roc_curve(test_y, y_pred_rfc)\n",
    "auc_rfc = auc(fpr_rfc, tpr_rfc)\n",
    "\n",
    "# adaboost\n",
    "y_pred_abc = abc.predict_proba(test_x)[:,1]\n",
    "fpr_abc, tpr_abc, thresholds_abc = roc_curve(test_y, y_pred_abc)\n",
    "auc_abc = auc(fpr_abc, tpr_abc)\n",
    "\n",
    "# Gradient Boost\n",
    "y_pred_gbc = gbc.predict_proba(test_x)[:,1]\n",
    "fpr_gbc, tpr_gbc, thresholds_gbc = roc_curve(test_y, y_pred_gbc)\n",
    "auc_gbc = auc(fpr_gbc, tpr_gbc)\n",
    "\n",
    "# XGboost\n",
    "y_pred_xgb = xgb_clf.predict_proba(test_x)[:,1]\n",
    "fpr_xgb, tpr_xgb, thresholds_xgb = roc_curve(test_y, y_pred_xgb)\n",
    "auc_xgb = auc(fpr_xgb, tpr_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble model evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model predict values \n",
    "rfc_pred = rfc.predict(test_x)\n",
    "abc_pred = abc.predict(test_x)\n",
    "gbc_pred = gbc.predict(test_x)\n",
    "xgb_pred = xgb_clf.predict(test_x)\n",
    "\n",
    "# test_y values\n",
    "actual_value_array = test_y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN model\n",
    "##### Classification 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(10783, input_shape=(10783,),activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    #tf.keras.layers.Dropout(0.5), \n",
    "    \n",
    "    tf.keras.layers.Dense(8626, input_shape=(10783,),activation='relu'), \n",
    "    tf.keras.layers.BatchNormalization(axis=1, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones'),\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "    tf.keras.layers.Dense(6469, input_shape=(8626,),activation='relu'), \n",
    "    tf.keras.layers.BatchNormalization(axis=1, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones'),\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    tf.keras.layers.Dense(4313, input_shape=(6469,),activation='relu'), \n",
    "    tf.keras.layers.BatchNormalization(axis=1, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones'),\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    tf.keras.layers.Dense(2156, input_shape=(4313,),activation='relu'), \n",
    "    tf.keras.layers.BatchNormalization(axis=1, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones'),\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    tf.keras.layers.Dense(1, input_shape=(2156,),activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 219 samples, validate on 55 samples\n",
      "Epoch 1/100\n",
      "219/219 [==============================] - 114s 521ms/sample - loss: 3.5688 - acc: 0.5160 - val_loss: 132.9531 - val_acc: 0.5091\n",
      "Epoch 2/100\n",
      "219/219 [==============================] - 148s 678ms/sample - loss: 0.9263 - acc: 0.6575 - val_loss: 387.5581 - val_acc: 0.5091\n",
      "Epoch 3/100\n",
      "219/219 [==============================] - 164s 749ms/sample - loss: 0.5756 - acc: 0.7215 - val_loss: 154.8835 - val_acc: 0.5091\n",
      "Epoch 4/100\n",
      "219/219 [==============================] - 108s 495ms/sample - loss: 0.2963 - acc: 0.8539 - val_loss: 57.4584 - val_acc: 0.5091\n",
      "Epoch 5/100\n",
      "219/219 [==============================] - 121s 553ms/sample - loss: 0.1971 - acc: 0.9178 - val_loss: 31.0655 - val_acc: 0.5091\n",
      "Epoch 6/100\n",
      "219/219 [==============================] - 80s 367ms/sample - loss: 0.1724 - acc: 0.9224 - val_loss: 10.1729 - val_acc: 0.5091\n",
      "Epoch 7/100\n",
      "219/219 [==============================] - 93s 426ms/sample - loss: 0.1175 - acc: 0.9589 - val_loss: 22.0591 - val_acc: 0.5091\n",
      "Epoch 8/100\n",
      "219/219 [==============================] - 77s 353ms/sample - loss: 0.1620 - acc: 0.9315 - val_loss: 17.7486 - val_acc: 0.5091\n",
      "Epoch 9/100\n",
      "219/219 [==============================] - 121s 553ms/sample - loss: 0.0959 - acc: 0.9543 - val_loss: 12.1888 - val_acc: 0.5091\n",
      "Epoch 10/100\n",
      "219/219 [==============================] - 86s 393ms/sample - loss: 0.0863 - acc: 0.9635 - val_loss: 3.0337 - val_acc: 0.5091\n",
      "Epoch 11/100\n",
      "219/219 [==============================] - 97s 445ms/sample - loss: 0.2282 - acc: 0.9361 - val_loss: 3.1740 - val_acc: 0.5091\n",
      "Epoch 12/100\n",
      "219/219 [==============================] - 125s 570ms/sample - loss: 0.1060 - acc: 0.9589 - val_loss: 10.8837 - val_acc: 0.5091\n",
      "Epoch 13/100\n",
      "219/219 [==============================] - 130s 595ms/sample - loss: 0.1643 - acc: 0.9361 - val_loss: 3.4169 - val_acc: 0.5636\n",
      "Epoch 14/100\n",
      "219/219 [==============================] - 90s 411ms/sample - loss: 0.0669 - acc: 0.9680 - val_loss: 9.7920 - val_acc: 0.5091\n",
      "Epoch 15/100\n",
      "219/219 [==============================] - 130s 592ms/sample - loss: 0.0764 - acc: 0.9772 - val_loss: 2.1618 - val_acc: 0.5818\n",
      "Epoch 16/100\n",
      "100/219 [============>.................] - ETA: 1:13 - loss: 0.1286 - acc: 0.9700"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-69087e5baaf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#,callbacks=[tensorboard]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist=model1.fit(train_x, train_y, batch_size=25, epochs=100,validation_split=0.2)#,callbacks=[tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "y_pred_keras = model1.predict(test_x).ravel()\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(test_y, y_pred_keras)\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_rfc, tpr_rfc, label='Random Forest (area = {:.3f})'.format(auc_rfc))\n",
    "plt.plot(fpr_abc, tpr_abc, label='Adaboost (area = {:.3f})'.format(auc_abc))\n",
    "plt.plot(fpr_gbc, tpr_gbc, label='Gradient Boost (area = {:.3f})'.format(auc_gbc))\n",
    "plt.plot(fpr_xgb, tpr_xgb, label='XGBoost (area={:.3f})'.format(auc_xgb))\n",
    "plt.plot(fpr_keras, tpr_keras, label='DNN (area = {:.3f})'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('IRIS validation AUC using 10,783 features')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('./IRIS validation AUC using 10783 features', dpi=500, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model predict values \n",
    "DNN_pred = model1.predict(test_x)\n",
    "model_performance_DNN(test_x, model1, actual_value_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv(\"./IRIS_test.csv\")\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_value= test_set.drop([\"SampleID\", \"SSPG_classification\", \"SSPG\"],axis=1)\n",
    "test_interest = test_set.SSPG_classification\n",
    "\n",
    "print(\"Information of Training Data\")\n",
    "print(\"Samples : {}\".format(value.shape[0]))\n",
    "print(\"Features : {}\".format(value.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.array(test_value)\n",
    "test_X_MinMax = min_max_scaler.fit_transform(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "randomforest_pred = rfc.predict(test_X_MinMax)\n",
    "adaboost_pred = abc.predict(test_X_MinMax)\n",
    "gradient_pred = gbc.predict(test_X_MinMax)\n",
    "xgb_pred=xgb_clf.predict(test_X_MinMax)\n",
    "# DNN model predict values\n",
    "DNN_predict = model1.predict_classes(test_X_MinMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "y_pred_rfc2 = rfc.predict_proba(test_X_MinMax)[:,1]\n",
    "fpr_rfc2, tpr_rfc2, thresholds_rfc2 = roc_curve(test_interest, y_pred_rfc2)\n",
    "auc_rfc2 = auc(fpr_rfc2, tpr_rfc2)\n",
    "\n",
    "# adaboost\n",
    "y_pred_abc2 = abc.predict_proba(test_X_MinMax)[:,1]\n",
    "fpr_abc2, tpr_abc2, thresholds_abc2 = roc_curve(test_interest, y_pred_abc2)\n",
    "auc_abc2 = auc(fpr_abc2, tpr_abc2)\n",
    "\n",
    "# Gradient Boost\n",
    "y_pred_gbc2 = gbc.predict_proba(test_X_MinMax)[:,1]\n",
    "fpr_gbc2, tpr_gbc2, thresholds_gbc2 = roc_curve(test_interest, y_pred_gbc2)\n",
    "auc_gbc2 = auc(fpr_gbc2, tpr_gbc2)\n",
    "\n",
    "# XGboost\n",
    "y_pred_xgb2 = xgb_clf.predict_proba(test_X_MinMax)[:,1]\n",
    "fpr_xgb2, tpr_xgb2, thresholds_xgb2 = roc_curve(test_interest, y_pred_xgb2)\n",
    "auc_xgb2 = auc(fpr_xgb2, tpr_xgb2)\n",
    "\n",
    "\n",
    "y_pred_keras2 = model1.predict(test_X_MinMax).ravel()\n",
    "fpr_keras2, tpr_keras2, thresholds_keras2 = roc_curve(test_interest, y_pred_keras2)\n",
    "auc_keras2 = auc(fpr_keras2, tpr_keras2)\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_rfc2, tpr_rfc2, label='Random Forest (area = {:.3f})'.format(auc_rfc2))\n",
    "plt.plot(fpr_abc2, tpr_abc2, label='Adaboost (area = {:.3f})'.format(auc_abc2))\n",
    "plt.plot(fpr_gbc2, tpr_gbc2, label='Gradient Boost (area = {:.3f})'.format(auc_gbc2))\n",
    "plt.plot(fpr_xgb2, tpr_xgb2, label='XGBoost (area={:.3f})'.format(auc_xgb2))\n",
    "plt.plot(fpr_keras2, tpr_keras2, label='DNN (area = {:.3f})'.format(auc_keras2))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('IRIS test AUC using 10,783 features')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('./IRIS test AUC using 10783 features', dpi=500, bbox_inches = 'tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
